{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import glob as gb\n",
    "import numpy as np\n",
    "import glob as gb\n",
    "import os\n",
    "import h5py\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "from keras.layers import Input, concatenate\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers.convolutional import Convolution2D\n",
    "from keras.layers.core import Dropout, Dense, Flatten, Lambda\n",
    "from keras.layers.merge import Average\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.models import Model\n",
    "from keras.utils.vis_utils import plot_model\n",
    "import keras.backend as K\n",
    "import numpy as np\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_shape = (256, 256, 3)\n",
    "K_1 = 145\n",
    "K_2 = 170\n",
    "channel_rate = 64\n",
    "patch_shape = (channel_rate, channel_rate, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalization(x):\n",
    "    return x / 127.5 - 1\n",
    "\n",
    "def formatImage(path, size):\n",
    "    inImage = Image.open(path)\n",
    "    fImage = inImage.crop((0, 0, inImage.size[0] / 2, inImage.size[1]))\n",
    "    bImage = inImage.crop((inImage.size[0] / 2, 0, inImage.size[0], inImage.size[1]))\n",
    "\n",
    "    fImage = fImage.resize((size, size), Image.ANTIALIAS)\n",
    "    bImage = bImage.resize((size, size), Image.ANTIALIAS)\n",
    "\n",
    "    return np.array(fImage), np.array(b_Image)\n",
    "\n",
    "def buildHDF5(jpeg_dir, size=256):\n",
    "    hdf5_file = os.path.join('data', 'data.h5')\n",
    "    with h5py.File(hdf5_file, 'w') as f:\n",
    "\n",
    "        for data_type in tqdm(['train', 'test'], desc='create HDF5 dataset from images'):\n",
    "            dataPath = jpeg_dir + '/%s/*.jpg' % data_type\n",
    "            imagesPath = gb.glob(dataPath)\n",
    "            fData = []\n",
    "            bData = []\n",
    "            for imagePath in imagesPath:\n",
    "                fImage, bImage = formatImage(imagePath, size)\n",
    "                fData.append(fImage)\n",
    "                bData.append(bImage)\n",
    "\n",
    "            f.create_dataset('%s_data_full' % data_type, data=fData)\n",
    "            f.create_dataset('%s_data_blur' % data_type, data=bData)\n",
    "\n",
    "def loadData(data_type):\n",
    "    with h5py.File('data/data.h5', 'r') as f:\n",
    "        fData = f['%s_data_full' % data_type][:].astype(np.float32)\n",
    "        fData = normalization(fData)\n",
    "\n",
    "        bData = f['%s_data_blur' % data_type][:].astype(np.float32)\n",
    "        bData = normalization(bData)\n",
    "\n",
    "        return fData, bData\n",
    "\n",
    "\n",
    "def generateImage(full, blur, generated, path, epoch=None, index=None):\n",
    "    full = full * 127.5 + 127.5\n",
    "    blur = blur * 127.5 + 127.5\n",
    "    generated = generated * 127.5 + 127.5\n",
    "    for i in range(generated.shape[0]):\n",
    "        fImage = full[i, :, :, :]\n",
    "        bImage = blur[i, :, :, :]\n",
    "        gImage = generated[i, :, :, :]\n",
    "        image = np.concatenate((fImage, bImage, gImage), axis=1)\n",
    "        if (epoch is not None) and (index is not None):\n",
    "            Image.fromarray(image.astype(np.uint8)).save(path + str(epoch + 1) + '_' + str(index + 1) + '.png')\n",
    "        else:\n",
    "            Image.fromarray(image.astype(np.uint8)).save(path + str(i) + '.png')\n",
    "    \n",
    "def lossL1(yTrue, yPred):\n",
    "    return K.mean(K.abs(yPred - yTrue))\n",
    "\n",
    "def lossPerceptual(yTrue, yPred):\n",
    "    vgg = VGG16(include_top=False, weights='imagenet', input_shape=image_shape)\n",
    "    lossModel = Model(inputs=vgg.input, outputs=vgg.get_layer('block3_conv3').output)\n",
    "    lossModel.trainable = False\n",
    "    return K.mean(K.square(lossModel(yTrue) - lossModel(yPred)))\n",
    "\n",
    "def lossGenerator(yTrue, yPred):\n",
    "    return K_1 * lossPerceptual(yTrue, yPred) + K_2 * lossL1(yTrue, yPred)\n",
    "\n",
    "def lossAdversarial(yTrue, yPred):\n",
    "    return -K.log(yPred)\n",
    "\n",
    "def denseBlock(inputs, dilationFactor=None):\n",
    "    x = LeakyReLU(alpha=0.2)(inputs)\n",
    "    x = Convolution2D(filters=4 * channel_rate, kernel_size=(1, 1), padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "    \n",
    "    if dilationFactor is not None:\n",
    "        x = Convolution2D(filters=channel_rate, kernel_size=(3, 3), padding='same',\n",
    "                          dilation_rate=dilationFactor)(x)\n",
    "    else:\n",
    "        x = Convolution2D(filters=channel_rate, kernel_size=(3, 3), padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(rate=0.5)(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def generatorModel():\n",
    "    in_gen = Input(shape=(None, None, 3))\n",
    "    head = Convolution2D(filters=4 * channel_rate, kernel_size=(3, 3), padding='same')(in_gen)\n",
    "    dense1 = denseBlock(inputs=head)\n",
    "    x = concatenate([head, dense1])\n",
    "    dense2 = denseBlock(inputs=x, dilationFactor=(1, 1))\n",
    "    x = concatenate([x, dense2])\n",
    "    dense3 = denseBlock(inputs=x)\n",
    "    x = concatenate([x, dense3])\n",
    "    dense4 = denseBlock(inputs=x, dilationFactor=(2, 2))\n",
    "    x = concatenate([x, dense4])\n",
    "    dense5 = denseBlock(inputs=x)\n",
    "    x = concatenate([x, dense5])\n",
    "    dense6 = denseBlock(inputs=x, dilationFactor=(3, 3))\n",
    "    x = concatenate([x, dense6])\n",
    "    dense7 = denseBlock(inputs=x)\n",
    "    x = concatenate([x, dense7])\n",
    "    dense8 = denseBlock(inputs=x, dilationFactor=(2, 2))\n",
    "    x = concatenate([x, dense8])\n",
    "    dense9 = denseBlock(inputs=x)\n",
    "    x = concatenate([x, dense9])\n",
    "    dense10 = denseBlock(inputs=x, dilationFactor=(1, 1))\n",
    "    x = LeakyReLU(alpha=0.2)(dense10)\n",
    "    x = Convolution2D(filters=4 * channel_rate, kernel_size=(1, 1), padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = concatenate([head, x])\n",
    "    x = Convolution2D(filters=channel_rate, kernel_size=(3, 3), padding='same')(x)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "    out_gen = Convolution2D(filters=3, kernel_size=(3, 3), padding='same', activation='tanh')(x)\n",
    "    \n",
    "    model = Model(inputs=in_gen, outputs=out_gen, name='Generator')\n",
    "    return model\n",
    "\n",
    "\n",
    "def discriminatorModel():\n",
    "    in_dis = Input(shape=patch_shape)\n",
    "    x = Convolution2D(filters=channel_rate, kernel_size=(3, 3), strides=(2, 2), padding=\"same\")(in_dis)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "    x = Convolution2D(filters=2 * channel_rate, kernel_size=(3, 3), strides=(2, 2), padding=\"same\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "    x = Convolution2D(filters=4 * channel_rate, kernel_size=(3, 3), strides=(2, 2), padding=\"same\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "    x = Convolution2D(filters=4 * channel_rate, kernel_size=(3, 3), strides=(2, 2), padding=\"same\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "    x = Flatten()(x)\n",
    "    out_dis = Dense(units=1, activation='sigmoid')(x)\n",
    "    model = Model(inputs=in_dis, outputs=out_dis, name='Discriminator')\n",
    "\n",
    "    inputs = Input(shape=image_shape)\n",
    "\n",
    "    list_row_idx = [(i * channel_rate, (i + 1) * channel_rate) for i in\n",
    "                    range(int(image_shape[0] / patch_shape[0]))]\n",
    "    list_col_idx = [(i * channel_rate, (i + 1) * channel_rate) for i in\n",
    "                    range(int(image_shape[1] / patch_shape[1]))]\n",
    "\n",
    "    list_patch = []\n",
    "    for row_idx in list_row_idx:\n",
    "        for col_idx in list_col_idx:\n",
    "            x_patch = Lambda(lambda z: z[:, row_idx[0]:row_idx[1], col_idx[0]:col_idx[1], :])(inputs)\n",
    "            list_patch.append(x_patch)\n",
    "\n",
    "    x = [model(patch) for patch in list_patch]\n",
    "    outputs = Average()(x)\n",
    "    model = Model(inputs=inputs, outputs=outputs, name='Discriminator')\n",
    "    return model\n",
    "\n",
    "def generatorWithDiscriminator(generator, discriminator):\n",
    "    inputs = Input(shape=image_shape)\n",
    "    generated_image = generator(inputs)\n",
    "    outputs = discriminator(generated_image)\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    return model\n",
    "\n",
    "def train(batch_size, epoch_num):\n",
    "    yTrain, xTrain = loadData(data_type='train')\n",
    "\n",
    "    g = generatorModel()\n",
    "    d = discriminatorModel()\n",
    "    d_on_g = generatorWithDiscriminator(g, d)\n",
    "\n",
    "    g.compile(optimizer='adam', loss=lossGenerator)\n",
    "    d.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "    d_on_g.compile(optimizer='adam', loss=lossAdversarial)\n",
    "\n",
    "    for epoch in range(epoch_num):\n",
    "        print('epoch: ', epoch + 1, '/', epoch_num)\n",
    "        print('batches: ', int(xTrain.shape[0] / batch_size))\n",
    "\n",
    "        for index in range(int(xTrain.shape[0] / batch_size)):\n",
    "            bImageBatch = xTrain[index * batch_size:(index + 1) * batch_size]\n",
    "            fImageBatch = yTrain[index * batch_size:(index + 1) * batch_size]\n",
    "            gImages = g.predict(x=bImageBatch, batch_size=batch_size)\n",
    "\n",
    "            if (index % 30 == 0) and (index != 0):\n",
    "                generateImage(fImageBatch, bImageBatch, gImages,\n",
    "                                          'result/interim/', epoch, index)\n",
    "\n",
    "            x = np.concatenate((fImageBatch, gImages))\n",
    "\n",
    "            y = [1] * batch_size + [0] * batch_size\n",
    "\n",
    "            dLoss = d.train_on_batch(x, y)\n",
    "            print('batch %d d_loss : %f' % (index + 1, dLoss))\n",
    "\n",
    "            d.trainable = False\n",
    "\n",
    "            d_on_gLoss = d_on_g.train_on_batch(bImageBatch, [1] * batch_size)\n",
    "            print('batch %d d_on_g_loss : %f' % (index + 1, d_on_gLoss))\n",
    "\n",
    "            gLoss = g.train_on_batch(bImageBatch, fImageBatch)\n",
    "            print('batch %d g_loss : %f' % (index + 1, gLoss))\n",
    "\n",
    "            d.trainable = True\n",
    "\n",
    "            if (index % 30 == 0) and (index != 0):\n",
    "                g.save_weights('weight/generator_weights.h5', True)\n",
    "                d.save_weights('weight/discriminator_weights.h5', True)\n",
    "\n",
    "\n",
    "def test(batch_size):\n",
    "    yTest, xTest = loadData(data_type='test')\n",
    "    g = generatorModel()\n",
    "    g.load_weights('weight/generator_weights.h5')\n",
    "    gImages = g.predict(x=xTest, batch_size=batch_size)\n",
    "    generateImage(yTest, xTest, gImages, 'result/final/')\n",
    "\n",
    "\n",
    "def testPictures(batch_size):\n",
    "    dataPath = 'data/test/*.jpeg'\n",
    "    imagesPath = gb.glob(dataPath)\n",
    "    bData = []\n",
    "    for imagePath in imagesPath:\n",
    "        bImage = Image.open(imagePath)\n",
    "        bData.append(np.array(bImage))\n",
    "\n",
    "    bData = np.array(bData).astype(np.float32)\n",
    "    bData = normalization(bData)\n",
    "\n",
    "    g = generatorModel()\n",
    "    g.load_weights('weight/generator_weights.h5')\n",
    "    gImages = g.predict(x=bData, batch_size=batch_size)\n",
    "    generated = gImages * 127.5 + 127.5\n",
    "    for i in range(generated.shape[0]):\n",
    "        image_generated = generated[i, :, :, :]\n",
    "        Image.fromarray(image_generated.astype(np.uint8)).save('result/test/' + str(i) + '.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  1 / 10\n",
      "batches:  302\n"
     ]
    }
   ],
   "source": [
    "train(batch_size=2, epoch_num=10)\n",
    "test(4)\n",
    "testPictures(2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
